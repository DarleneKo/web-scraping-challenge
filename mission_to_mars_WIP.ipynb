{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1:  Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows Users\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for Mars News using Splinter\n",
    "news_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(news_url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html'\n",
    "news_html = browser.html\n",
    "news_soup = BeautifulSoup(news_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus \n"
     ]
    }
   ],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest News Title)\n",
    "list_text = news_soup.find('div', class_='list_text')\n",
    "news_title = list_text.find('div', class_='content_title').find('a').text\n",
    "\n",
    "# Print the scraped information\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.\n"
     ]
    }
   ],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest News Paragraph)\n",
    "news_p = list_text.find('div', class_='article_teaser_body').text\n",
    "\n",
    "# Print the scraped information\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for JPL Featured Space Image using Splinter\n",
    "image_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(image_url)\n",
    "time.sleep(1)\n",
    "\n",
    "# Find the Full Image Button on the Website\n",
    "button = browser.links.find_by_partial_text('FULL IMAGE')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html' (1st Website Page)\n",
    "image_html = browser.html\n",
    "image_soup = BeautifulSoup(image_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"button fancybox\" data-description=\"This image was taken by the Optical, Spectroscopic, and Infrared Remote Imaging System, Rosetta's main onboard scientific imaging system, on Sept. 10, 2014. Jets of cometary activity can be seen along almost the entire body of the comet.\" data-fancybox-group=\"images\" data-fancybox-href=\"/spaceimages/images/mediumsize/PIA18886_ip.jpg\" data-link=\"/spaceimages/details.php?id=PIA18886\" data-title=\"Rosetta Comet Spreads its Jets\" id=\"full_image\">\n",
      "\t\t\t\t\tFULL IMAGE\n",
      "\t\t\t\t  </a>\n"
     ]
    }
   ],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Image)\n",
    "footer = image_soup.find('a', class_=\"button fancybox\")\n",
    "\n",
    "# Print the scraped information\n",
    "print(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the Full Image Button on the Website\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html' (2nd Website Page after Clicking Button)\n",
    "full_image_html = browser.html\n",
    "full_image_soup = BeautifulSoup(full_image_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Full Image after Clicking Button)\n",
    "full_image = full_image_soup.find('img', class_='fancybox-image')\n",
    "\n",
    "# Print the scraped information\n",
    "print(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'attrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8e0a33ee7249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract the inner attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print the scraped information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'attrs'"
     ]
    }
   ],
   "source": [
    "# Extract the inner attribute\n",
    "image_url = full_image.attrs['src']\n",
    "\n",
    "# Print the scraped information\n",
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine main url page with the full image url for the final url\n",
    "main_jpl_url = \"https://www.jpl.nasa.gov\"\n",
    "featured_image_url = f'{main_jpl_url}{image_url}'\n",
    "\n",
    "# Print the scraped information\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for the Mars Weather Twitter Account using Splinter\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)\n",
    "time.sleep(1)\n",
    "\n",
    "#tab = browser.links.find_by_partial_text('Tweets')\n",
    "#time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html'\n",
    "weather_html = browser.html\n",
    "weather_soup = BeautifulSoup(weather_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Tweet)\n",
    "weather_timeline = weather_soup.find('div', attrs={\"aria-label\": \"Timeline: Mars Weatherâ€™s Tweets\"})\n",
    "\n",
    "# Print the scraped information\n",
    "print(weather_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Tweet)\n",
    "latest_tweet = weather_timeline.find('div',\n",
    "                                     attrs={'lang': 'en',\n",
    "                                           'dir': 'auto',\n",
    "                                           'class': 'css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0'})\n",
    "# Print the scraped information\n",
    "print(latest_tweet)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Tweet)\n",
    "mars_weather = latest_tweet.find('span', class_='css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0').text\n",
    "\n",
    "# Print the scraped information\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the read_html function in Pandas to automatically scrape any tabular data from a page.\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "tables = pd.read_html(facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we get in return is a list of dataframes for any tabular data that Pandas found.\n",
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can slice off any of those dataframes that we want using normal indexing.\n",
    "df = tables[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the columns `['Description', 'Value']`\n",
    "df.columns = ['Description','Value']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the `Description` column without row indexing\n",
    "df.set_index('Description', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the table directly to a file.\n",
    "\n",
    "df.to_html('mars_table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for the USGS Astrogeology site using Splinter\n",
    "hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemispheres_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html'\n",
    "hemispheres_html = browser.html\n",
    "hemispheres_soup = BeautifulSoup(hemispheres_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print formatted version of the soup\n",
    "#print(hemispheres_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info (Latest Tweet) by looping through Results\n",
    "\n",
    "for y in range(1, 5):\n",
    "\n",
    "    hemispheres_html = browser.html\n",
    "    hemispheres_soup = BeautifulSoup(hemispheres_html, 'html.parser')\n",
    "\n",
    "    hemispheres = hemispheres_soup.find_all('a', class_='itemLink product-item')\n",
    "\n",
    "    for hemisphere in hemispheres:\n",
    "        print('page:', y, '-------------------------------------------------------------------------------------------')\n",
    "        print(hemisphere.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
